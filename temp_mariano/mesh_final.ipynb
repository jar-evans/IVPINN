{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:36:02.416597: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-18 02:36:02.417881: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 02:36:02.450250: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-18 02:36:02.450825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-18 02:36:03.037382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings_lib imported \n",
      "interpolator_lib imported\n",
      "mesh_lib imported\n",
      "settings_lib imported \n",
      "mesh_lib imported\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import settings\n",
    "import VPINN_tri_final\n",
    "import mesh_lib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from GaussJacobiQuadRule_V3 import Jacobi, DJacobi, GaussLobattoJacobiWeights\n",
    "import os \n",
    "\n",
    "importlib.reload(settings)\n",
    "importlib.reload(mesh_lib)\n",
    "importlib.reload(VPINN_tri_final)\n",
    "\n",
    "from settings import *\n",
    "from mesh_lib import *\n",
    "from VPINN_tri_final import *\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree =  2  , local dof =  6  internal dof =  0  points inside each edge =  1\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1/2 0]\n",
      " [1/2 1/2]\n",
      " [0 1/2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basis=interpolator(2,False,False,points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import triangle as tr\n",
    "\n",
    "# Step 1: Generate a fine mesh\n",
    "A = dict(vertices=np.array(((0, 0), (1, 0), (1, 1), (0, 1))))\n",
    "B = tr.triangulate(A, 'qnea0.05')\n",
    "tr.compare(plt,A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import triangle as tr\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Generate a fine mesh\n",
    "A = dict(vertices=np.array(((0, 0), (1, 0), (1, 1), (0, 1))))\n",
    "B = tr.triangulate(A,'qnea0.1')\n",
    "\n",
    "tr.compare(plt, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 12]\n",
      " [ 9 12]\n",
      " [ 4  9]\n",
      " [ 4  8]\n",
      " [ 4  5]\n",
      " [ 5  8]\n",
      " [ 7 10]\n",
      " [ 3  7]\n",
      " [ 3 10]\n",
      " [ 3  5]\n",
      " [ 5 10]\n",
      " [ 4  6]\n",
      " [ 6 12]\n",
      " [ 6  8]\n",
      " [ 0  6]\n",
      " [ 0  8]\n",
      " [ 2 11]\n",
      " [ 2  7]\n",
      " [ 7 11]\n",
      " [ 0  5]\n",
      " [ 2  9]\n",
      " [ 9 11]\n",
      " [ 4  7]\n",
      " [ 4 10]\n",
      " [ 4 11]\n",
      " [ 1  9]\n",
      " [ 1 12]\n",
      " [ 1  6]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#edges flipping \n",
    "\n",
    "for i in range(len(B['edges'])):\n",
    "    ii=B['edges'][i][0]\n",
    "    jj=B['edges'][i][1]\n",
    "\n",
    "    if ii>jj:\n",
    "            B['edges'][i][0],B['edges'][i][1]=B['edges'][i][1],B['edges'][i][0]\n",
    "\n",
    "tr.compare(plt, A, B)\n",
    "\n",
    "print(B['edges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#util functions\n",
    "\n",
    "def get_triangle_edges(triangle_vertices,edges):\n",
    "    triangle_edges = []\n",
    " \n",
    "\n",
    "    keep=np.zeros((3,),dtype=np.int64)\n",
    "\n",
    "    for i in range(3):\n",
    "        ii=triangle_vertices[i].copy()\n",
    "        jj=triangle_vertices[(i + 1) % 3].copy()\n",
    "        \n",
    "\n",
    "        if(ii>jj):\n",
    "            edge=np.array([jj,ii])\n",
    "        else:\n",
    "            edge=np.array([ii,jj])\n",
    "\n",
    "        index= np.where(np.all(edges == edge, axis=1))[0][0]\n",
    "        \n",
    "        triangle_edges.append(index)\n",
    "\n",
    "        if ii>jj:\n",
    "            keep[i]=1\n",
    "\n",
    "    triangle_edges=np.array(triangle_edges)\n",
    "        \n",
    "    return keep,triangle_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flipping part + edges\n",
    "l=[]\n",
    "temp=[]\n",
    "for triangle in B['triangles']:\n",
    "    keep,t=get_triangle_edges(triangle,B['edges'])\n",
    "    l.append(keep)\n",
    "    temp.append(t)\n",
    "\n",
    "\n",
    "\n",
    "keep=np.asarray(l)\n",
    "edges_index_inside_triangle=np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B['keep']=keep\n",
    "B['edges_index_inside_triangle']=edges_index_inside_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vertices', 'vertex_markers', 'triangles', 'neighbors', 'edges', 'edge_markers', 'keep', 'edges_index_inside_triangle'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 12]\n",
      " [ 9 12]\n",
      " [ 4  9]\n",
      " [ 4  8]\n",
      " [ 4  5]\n",
      " [ 5  8]\n",
      " [ 7 10]\n",
      " [ 3  7]\n",
      " [ 3 10]\n",
      " [ 3  5]\n",
      " [ 5 10]\n",
      " [ 4  6]\n",
      " [ 6 12]\n",
      " [ 6  8]\n",
      " [ 0  6]\n",
      " [ 0  8]\n",
      " [ 2 11]\n",
      " [ 2  7]\n",
      " [ 7 11]\n",
      " [ 0  5]\n",
      " [ 2  9]\n",
      " [ 9 11]\n",
      " [ 4  7]\n",
      " [ 4 10]\n",
      " [ 4 11]\n",
      " [ 1  9]\n",
      " [ 1 12]\n",
      " [ 1  6]]\n",
      "[[6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [0.]\n",
      " [6.]\n",
      " [0.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [0.]\n",
      " [6.]\n",
      " [6.]\n",
      " [0.]\n",
      " [6.]\n",
      " [0.]\n",
      " [0.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [6.]\n",
      " [0.]\n",
      " [6.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#exp\n",
    "n_vertices=len(B['vertices'])\n",
    "n_traingles=len(B['triangles'])\n",
    "n_edges=len(B['edges'])\n",
    "\n",
    "n_inside_edge=basis.n_inside_edge\n",
    "n_inside=basis.n_inside\n",
    "\n",
    "vertices_contribution=np.zeros((n_vertices,1))\n",
    "edges_contribution=np.zeros((n_edges,n_inside_edge))\n",
    "inside_contribution=np.zeros((n_traingles,n_inside))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for index,triangle in enumerate(B['triangles']):\n",
    "\n",
    "\n",
    "    if (B['vertex_markers'][triangle[0]]==0):\n",
    "            vertices_contribution[triangle[0]]=1\n",
    "    else:\n",
    "          vertices_contribution[triangle[0]]=2\n",
    "\n",
    "    if (B['vertex_markers'][triangle[1]]==0):\n",
    "            vertices_contribution[triangle[1]]=1\n",
    "    else:\n",
    "          vertices_contribution[triangle[1]]=2    \n",
    "\n",
    "    if (B['vertex_markers'][triangle[2]]==0):\n",
    "            vertices_contribution[triangle[2]]=1\n",
    "    else:\n",
    "          vertices_contribution[triangle[2]]=2\n",
    "    \n",
    "\n",
    "    if(B['edge_markers'][B['edges_index_inside_triangle'][index][0]]==0):\n",
    "           \n",
    "           edges_contribution[B['edges_index_inside_triangle'][index][0]]+=3\n",
    "\n",
    "    if(B['edge_markers'][B['edges_index_inside_triangle'][index][1]]==0):\n",
    "           edges_contribution[B['edges_index_inside_triangle'][index][1]]+=3\n",
    "\n",
    "    if(B['edge_markers'][B['edges_index_inside_triangle'][index][2]]==0):\n",
    "           edges_contribution[B['edges_index_inside_triangle'][index][2]]+=3      \n",
    "\n",
    "\n",
    "\n",
    "print(B['edges'])\n",
    "print(edges_contribution)\n",
    "\n",
    "\n",
    "    \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk=tf.keras\n",
    "tfkl=tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfk.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(2,),dtype=tf.float64))\n",
    "model.add(tfkl.Dense(10, activation='tanh',kernel_initializer=\"glorot_uniform\",dtype=tf.float64,bias_initializer=\"glorot_uniform\"))\n",
    "model.add(tfkl.Dense(10, activation='tanh',kernel_initializer=\"glorot_uniform\",dtype=tf.float64,bias_initializer=\"glorot_uniform\"))\n",
    "model.add(tfkl.Dense(10, activation='tanh',kernel_initializer=\"glorot_uniform\",dtype=tf.float64,bias_initializer=\"glorot_uniform\"))\n",
    "model.add(tfkl.Dense(10, activation='tanh',kernel_initializer=\"glorot_uniform\",dtype=tf.float64,bias_initializer=\"glorot_uniform\"))\n",
    "model.add(tf.keras.layers.Dense(1,activation='linear',kernel_initializer=\"glorot_uniform\",dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371 (2.90 KB)\n",
      "Trainable params: 371 (2.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "(None, 2)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense/kernel:0' shape=(2, 10) dtype=float64, numpy=\n",
      "array([[-0.07024012,  0.15473907,  0.46016778,  0.05468002, -0.53563901,\n",
      "         0.033466  ,  0.39357909,  0.36560743,  0.21358696, -0.495634  ],\n",
      "       [ 0.17312787, -0.03171857,  0.5718265 ,  0.02224777, -0.19421677,\n",
      "         0.07128324,  0.40466137, -0.07746155,  0.29825722, -0.51990431]])>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([-0.10614405,  0.00597241,  0.36982701, -0.10817956,  0.18692694,\n",
      "        0.33615439,  0.45528085, -0.00881405,  0.1296024 ,  0.50080848])>, <tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[ 0.1081156 , -0.15835508, -0.50316157,  0.30943277, -0.17464874,\n",
      "         0.32694343, -0.23681989, -0.45165213,  0.15774089,  0.48228697],\n",
      "       [ 0.23264397,  0.2188589 , -0.22397215,  0.2819821 , -0.2566888 ,\n",
      "        -0.04497333, -0.37869011,  0.10009616,  0.38766648,  0.43793387],\n",
      "       [-0.05796043, -0.2553875 , -0.18923088,  0.5468451 , -0.17211184,\n",
      "         0.24666583, -0.23641215, -0.20311939,  0.26176149,  0.02254073],\n",
      "       [ 0.35962359,  0.34560928,  0.34444222,  0.2009632 , -0.52646307,\n",
      "         0.4671817 ,  0.50520112, -0.21413478, -0.18829125,  0.51975349],\n",
      "       [-0.3228141 ,  0.28694336, -0.19715314, -0.34667374,  0.22538269,\n",
      "         0.21031931,  0.39599951, -0.33802361,  0.22198085,  0.34596439],\n",
      "       [ 0.25402365, -0.50902655,  0.34098514,  0.40842783,  0.06238622,\n",
      "         0.02649211, -0.53076489,  0.40374103,  0.23180948, -0.32041499],\n",
      "       [ 0.01135677,  0.00480744, -0.25518471, -0.09309156, -0.07790478,\n",
      "        -0.25892934,  0.32821067, -0.43296685,  0.53623639, -0.29135846],\n",
      "       [ 0.09786104,  0.12070011, -0.04120691, -0.25886793,  0.22900795,\n",
      "         0.47674782, -0.28632618,  0.52728095,  0.27655705, -0.36765905],\n",
      "       [-0.41221111,  0.1866823 , -0.18515571, -0.19219705,  0.03852967,\n",
      "        -0.23825203,  0.22119385, -0.16192261, -0.54438697,  0.12253062],\n",
      "       [ 0.02333035,  0.46847737, -0.35061617,  0.12488083,  0.2597767 ,\n",
      "        -0.15540304, -0.4702989 , -0.00257897, -0.13763589,  0.13232872]])>, <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([ 0.23911299, -0.52734476, -0.15958556,  0.34186997, -0.32920221,\n",
      "        0.48154579,  0.36909855,  0.09723048,  0.30939766, -0.33922465])>, <tf.Variable 'dense_2/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[ 0.4936905 ,  0.27054296, -0.19100789, -0.20454013, -0.41726927,\n",
      "         0.28365541,  0.41912089,  0.34719117, -0.18258477, -0.0709683 ],\n",
      "       [-0.00952683,  0.22156615,  0.34371198,  0.35529404, -0.07946655,\n",
      "         0.00557638,  0.13198625,  0.38466415,  0.14698267, -0.18143729],\n",
      "       [ 0.28241486,  0.10684205, -0.32443559,  0.02641225,  0.36069262,\n",
      "        -0.41007879, -0.45604288, -0.43649003,  0.18413927, -0.49314824],\n",
      "       [ 0.1595744 , -0.45139437,  0.13573025,  0.46619927, -0.37002511,\n",
      "        -0.18615273, -0.22744328,  0.49508001,  0.26357797, -0.27716808],\n",
      "       [-0.202301  , -0.30478908, -0.36158149,  0.39518757,  0.04500789,\n",
      "        -0.38056206, -0.11259911,  0.4097558 ,  0.02987542, -0.12177226],\n",
      "       [-0.09974605,  0.36557718,  0.0230226 ,  0.28653866,  0.46018878,\n",
      "         0.00359014, -0.5392086 , -0.03012131,  0.0747941 , -0.26533943],\n",
      "       [ 0.26314692,  0.14323186,  0.29169483,  0.17556742,  0.31147113,\n",
      "         0.11072359, -0.32462837, -0.53343926,  0.27703694, -0.47787223],\n",
      "       [ 0.15798936,  0.49968858,  0.51739008,  0.21515546, -0.45394306,\n",
      "        -0.29272685,  0.15603454, -0.0121707 ,  0.43291235,  0.30407808],\n",
      "       [-0.22755142,  0.4593084 , -0.02120684,  0.4551786 , -0.1854946 ,\n",
      "         0.39404863, -0.16603071,  0.11460055,  0.4136516 , -0.24741839],\n",
      "       [-0.03810581,  0.45294768,  0.05189123,  0.03928116, -0.36381099,\n",
      "         0.47601807,  0.34013592, -0.14097942, -0.20995071,  0.42477359]])>, <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([-0.2902871 , -0.23383709, -0.3955482 , -0.1576305 ,  0.53963064,\n",
      "       -0.46081679,  0.46528912, -0.39073484, -0.17907884, -0.44389535])>, <tf.Variable 'dense_3/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[-0.21124595, -0.36966515, -0.07623466, -0.48497772, -0.13263078,\n",
      "        -0.08098136,  0.00061671,  0.44383545, -0.48305161,  0.11550026],\n",
      "       [-0.50068095, -0.34185836,  0.01901734,  0.2269398 , -0.03198903,\n",
      "         0.21232571,  0.23448527,  0.19089184, -0.29751948, -0.25924399],\n",
      "       [-0.03346568,  0.5020776 , -0.0326204 ,  0.3669923 , -0.16838565,\n",
      "         0.2414627 ,  0.19301571, -0.34546851, -0.19862554,  0.29211226],\n",
      "       [-0.06122206,  0.54740359, -0.44373696, -0.2790735 ,  0.39559214,\n",
      "         0.54648502, -0.47404929, -0.05920097, -0.32946713, -0.30287233],\n",
      "       [ 0.13020874,  0.53620338,  0.06960244, -0.09911551, -0.23108996,\n",
      "         0.37543839, -0.3103918 ,  0.2951911 ,  0.44935572, -0.49307687],\n",
      "       [-0.17869492, -0.11593937, -0.1557629 , -0.13372195, -0.49279691,\n",
      "         0.04717506, -0.24131013,  0.13673953,  0.0609745 , -0.18470231],\n",
      "       [ 0.23013063,  0.49258387,  0.33422171,  0.37560365,  0.41494828,\n",
      "        -0.243518  , -0.40901572,  0.07870415,  0.52029748,  0.26158522],\n",
      "       [ 0.45464367, -0.37954102,  0.07823692, -0.39154237,  0.1319504 ,\n",
      "         0.50484203,  0.30700657, -0.07263784,  0.22508269,  0.20723559],\n",
      "       [-0.06077626, -0.17275187,  0.00165577, -0.4943126 ,  0.18446086,\n",
      "        -0.34200561,  0.07771707, -0.15297347, -0.47721718, -0.48919947],\n",
      "       [ 0.33093096,  0.50088204, -0.31993656, -0.40170224, -0.25339573,\n",
      "         0.2825774 ,  0.15320552, -0.54240769, -0.26261532, -0.42738586]])>, <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([-0.26792466, -0.54621362,  0.21878733, -0.32591998, -0.41136432,\n",
      "        0.10671803, -0.46778751, -0.25460115,  0.3372684 , -0.4498206 ])>, <tf.Variable 'dense_4/kernel:0' shape=(10, 1) dtype=float64, numpy=\n",
      "array([[-0.59386671],\n",
      "       [-0.41454228],\n",
      "       [-0.65646757],\n",
      "       [-0.05913531],\n",
      "       [ 0.66129619],\n",
      "       [ 0.15520354],\n",
      "       [-0.50371537],\n",
      "       [ 0.57140124],\n",
      "       [ 0.10961372],\n",
      "       [-0.50086669]])>, <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float64, numpy=array([0.])>]\n"
     ]
    }
   ],
   "source": [
    "print(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import *\n",
    "N_tests = 2\n",
    "N_elements = [5, 5]\n",
    "params = {'scheme': 'VPINNs',\n",
    "            'NN_struct': [2] + [5] * 3 + [1],\n",
    "            'var_form': 1,\n",
    "            'n_elements': tuple(N_elements),\n",
    "            'n_test': [N_elements[0]*[N_tests], N_elements[1]*[N_tests]],\n",
    "            'n_quad': 50,\n",
    "            'n_bound': 80, # for every edge \n",
    "            'n_residual': 100,\n",
    "            'domain': ((0.0, 1.0), (0.0, 1.0)),\n",
    "            'Opt_Niter': 15000 + 1,\n",
    "            'delta_test': 0.01,\n",
    "            'N_test':N_tests}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "degree =  2  , local dof =  6  internal dof =  0  points inside each edge =  1\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1/2 0]\n",
      " [1/2 1/2]\n",
      " [0 1/2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree =  2  , local dof =  6  internal dof =  0  points inside each edge =  1\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1/2 0]\n",
      " [1/2 1/2]\n",
      " [0 1/2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vp=VPINN(pb,params,B,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.6782826274659859>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.square(model(vp.boundary_points) - vp.u_bound_exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.01943047 -3.38357491 -1.09997987  0.95955137 -3.05385001 -1.87606661\n",
      "  -0.23192371  1.25089772 -0.48931642  0.09081072  0.90064717  1.63102336\n",
      "   1.47626404  1.59831901  1.76870333  1.92236972]\n",
      " [ 5.01943047  3.38357491  1.09997987 -0.95955137  3.05385001  1.87606661\n",
      "   0.23192371 -1.25089772  0.48931642 -0.09081072 -0.90064717 -1.63102336\n",
      "  -1.47626404 -1.59831901 -1.76870333 -1.92236972]]\n",
      "\n",
      "tf.Tensor(\n",
      "[[[ -5.01943047  -3.38357491  -1.09997987   0.95955137  -3.05385001\n",
      "    -1.87606661  -0.23192371   1.25089772  -0.48931642   0.09081072\n",
      "     0.90064717   1.63102336   1.47626404   1.59831901   1.76870333\n",
      "     1.92236972]\n",
      "  [  5.01943047   3.38357491   1.09997987  -0.95955137   3.05385001\n",
      "     1.87606661   0.23192371  -1.25089772   0.48931642  -0.09081072\n",
      "    -0.90064717  -1.63102336  -1.47626404  -1.59831901  -1.76870333\n",
      "    -1.92236972]]\n",
      "\n",
      " [[  0.           0.           0.           0.           0.\n",
      "     0.           0.           0.           0.           0.\n",
      "     0.           0.           0.           0.           0.\n",
      "     0.        ]\n",
      "  [  3.08633286  -0.42948822  -5.33744692  -9.76384217   3.08633286\n",
      "    -0.42948822  -5.33744692  -9.76384217   3.08633286  -0.42948822\n",
      "    -5.33744692  -9.76384217   3.08633286  -0.42948822  -5.33744692\n",
      "    -9.76384217]]\n",
      "\n",
      " [[ -1.47626404  -1.59831901  -1.76870333  -1.92236972   0.48931642\n",
      "    -0.09081072  -0.90064717  -1.63102336   3.05385001   1.87606661\n",
      "     0.23192371  -1.25089772   5.01943047   3.38357491   1.09997987\n",
      "    -0.95955137]\n",
      "  [ -1.47626404  -1.59831901  -1.76870333  -1.92236972   0.48931642\n",
      "    -0.09081072  -0.90064717  -1.63102336   3.05385001   1.87606661\n",
      "     0.23192371  -1.25089772   5.01943047   3.38357491   1.09997987\n",
      "    -0.95955137]]\n",
      "\n",
      " [[ -0.45683357  -2.21474411  -4.66872346  -6.88192109  -0.45683357\n",
      "    -2.21474411  -4.66872346  -6.88192109  -0.45683357  -2.21474411\n",
      "    -4.66872346  -6.88192109  -0.45683357  -2.21474411  -4.66872346\n",
      "    -6.88192109]\n",
      "  [-13.58202738  -8.5524057   -1.53123627   4.80102382  -9.65086646\n",
      "    -5.53738912   0.20487604   5.38371654  -4.52179927  -1.60363445\n",
      "     2.47001779   6.14396781  -0.59063834   1.41138214   4.20613011\n",
      "     6.72666052]]\n",
      "\n",
      " [[  0.45683357   2.21474411   4.66872346   6.88192109   0.45683357\n",
      "     2.21474411   4.66872346   6.88192109   0.45683357   2.21474411\n",
      "     4.66872346   6.88192109   0.45683357   2.21474411   4.66872346\n",
      "     6.88192109]\n",
      "  [ -0.59063834   1.41138214   4.20613011   6.72666052  -4.52179927\n",
      "    -1.60363445   2.47001779   6.14396781  -9.65086646  -5.53738912\n",
      "     0.20487604   5.38371654 -13.58202738  -8.5524057   -1.53123627\n",
      "     4.80102382]]\n",
      "\n",
      " [[  6.49569452   4.98189392   2.86868319   0.96281835   2.5645336\n",
      "     1.96687734   1.13257087   0.38012564  -2.5645336   -1.96687734\n",
      "    -1.13257087  -0.38012564  -6.49569452  -4.98189392  -2.86868319\n",
      "    -0.96281835]\n",
      "  [  7.54316643   5.78525589   3.33127654   1.11807891   7.54316643\n",
      "     5.78525589   3.33127654   1.11807891   7.54316643   5.78525589\n",
      "     3.33127654   1.11807891   7.54316643   5.78525589   3.33127654\n",
      "     1.11807891]]], shape=(6, 2, 16), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "_,c,J,B_D,B_DD=vp.b.change_of_coordinates(vp.mesh['vertices'][vp.mesh['triangles'][0]])\n",
    "\n",
    "t=np.array(vp.grad_test)[0]\n",
    "\n",
    "print((B_D@t))\n",
    "print()\n",
    "xy_quad_element=(B_D@ vp.grad_test)\n",
    "\n",
    "\n",
    "print(xy_quad_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.54700955 0.48572395]\n",
      "  [0.59431582 0.43078925]\n",
      "  [0.66035365 0.35410239]\n",
      "  [0.71991193 0.28493997]\n",
      "  [0.66985833 0.48572395]\n",
      "  [0.68853508 0.43078925]\n",
      "  [0.71460716 0.35410239]\n",
      "  [0.73812107 0.28493997]\n",
      "  [0.83014167 0.48572395]\n",
      "  [0.81146492 0.43078925]\n",
      "  [0.78539284 0.35410239]\n",
      "  [0.76187893 0.28493997]\n",
      "  [0.95299045 0.48572395]\n",
      "  [0.90568418 0.43078925]\n",
      "  [0.83964635 0.35410239]\n",
      "  [0.78008807 0.28493997]]\n",
      "\n",
      " [[0.2479093  0.2806428 ]\n",
      "  [0.30665822 0.33176328]\n",
      "  [0.38866959 0.40312563]\n",
      "  [0.46263409 0.46748598]\n",
      "  [0.18648491 0.34206719]\n",
      "  [0.25954859 0.37887292]\n",
      "  [0.36154283 0.43025238]\n",
      "  [0.45352951 0.47659055]\n",
      "  [0.10634324 0.42220886]\n",
      "  [0.19808367 0.44033784]\n",
      "  [0.32614999 0.46564522]\n",
      "  [0.44165059 0.48846948]\n",
      "  [0.04491885 0.48363325]\n",
      "  [0.15097404 0.48744747]\n",
      "  [0.29902324 0.49277198]\n",
      "  [0.43254601 0.49757405]]\n",
      "\n",
      " [[0.2479093  0.7806428 ]\n",
      "  [0.30665822 0.83176328]\n",
      "  [0.38866959 0.90312563]\n",
      "  [0.46263409 0.96748598]\n",
      "  [0.18648491 0.84206719]\n",
      "  [0.25954859 0.87887292]\n",
      "  [0.36154283 0.93025238]\n",
      "  [0.45352951 0.97659055]\n",
      "  [0.10634324 0.92220886]\n",
      "  [0.19808367 0.94033784]\n",
      "  [0.32614999 0.96564522]\n",
      "  [0.44165059 0.98846948]\n",
      "  [0.04491885 0.98363325]\n",
      "  [0.15097404 0.98744747]\n",
      "  [0.29902324 0.99277198]\n",
      "  [0.43254601 0.99757405]]\n",
      "\n",
      " [[0.01636675 0.95508115]\n",
      "  [0.01255253 0.84902596]\n",
      "  [0.00722802 0.70097676]\n",
      "  [0.00242595 0.56745399]\n",
      "  [0.07779114 0.89365676]\n",
      "  [0.05966216 0.80191633]\n",
      "  [0.03435478 0.67385001]\n",
      "  [0.01153052 0.55834941]\n",
      "  [0.15793281 0.81351509]\n",
      "  [0.12112708 0.74045141]\n",
      "  [0.06974762 0.63845717]\n",
      "  [0.02340945 0.54647049]\n",
      "  [0.2193572  0.7520907 ]\n",
      "  [0.16823672 0.69334178]\n",
      "  [0.09687437 0.61133041]\n",
      "  [0.03251402 0.53736591]]\n",
      "\n",
      " [[0.7193572  0.2479093 ]\n",
      "  [0.66823672 0.30665822]\n",
      "  [0.59687437 0.38866959]\n",
      "  [0.53251402 0.46263409]\n",
      "  [0.65793281 0.18648491]\n",
      "  [0.62112708 0.25954859]\n",
      "  [0.56974762 0.36154283]\n",
      "  [0.52340945 0.45352951]\n",
      "  [0.57779114 0.10634324]\n",
      "  [0.55966216 0.19808367]\n",
      "  [0.53435478 0.32614999]\n",
      "  [0.51153052 0.44165059]\n",
      "  [0.51636675 0.04491885]\n",
      "  [0.51255253 0.15097404]\n",
      "  [0.50722802 0.29902324]\n",
      "  [0.50242595 0.43254601]]\n",
      "\n",
      " [[0.48572395 0.45299045]\n",
      "  [0.43078925 0.40568418]\n",
      "  [0.35410239 0.33964635]\n",
      "  [0.28493997 0.28008807]\n",
      "  [0.48572395 0.33014167]\n",
      "  [0.43078925 0.31146492]\n",
      "  [0.35410239 0.28539284]\n",
      "  [0.28493997 0.26187893]\n",
      "  [0.48572395 0.16985833]\n",
      "  [0.43078925 0.18853508]\n",
      "  [0.35410239 0.21460716]\n",
      "  [0.28493997 0.23812107]\n",
      "  [0.48572395 0.04700955]\n",
      "  [0.43078925 0.09431582]\n",
      "  [0.35410239 0.16035365]\n",
      "  [0.28493997 0.21991193]]\n",
      "\n",
      " [[0.04491885 0.01636675]\n",
      "  [0.15097404 0.01255253]\n",
      "  [0.29902324 0.00722802]\n",
      "  [0.43254601 0.00242595]\n",
      "  [0.10634324 0.07779114]\n",
      "  [0.19808367 0.05966216]\n",
      "  [0.32614999 0.03435478]\n",
      "  [0.44165059 0.01153052]\n",
      "  [0.18648491 0.15793281]\n",
      "  [0.25954859 0.12112708]\n",
      "  [0.36154283 0.06974762]\n",
      "  [0.45352951 0.02340945]\n",
      "  [0.2479093  0.2193572 ]\n",
      "  [0.30665822 0.16823672]\n",
      "  [0.38866959 0.09687437]\n",
      "  [0.46263409 0.03251402]]\n",
      "\n",
      " [[0.7479093  0.7806428 ]\n",
      "  [0.80665822 0.83176328]\n",
      "  [0.88866959 0.90312563]\n",
      "  [0.96263409 0.96748598]\n",
      "  [0.68648491 0.84206719]\n",
      "  [0.75954859 0.87887292]\n",
      "  [0.86154283 0.93025238]\n",
      "  [0.95352951 0.97659055]\n",
      "  [0.60634324 0.92220886]\n",
      "  [0.69808367 0.94033784]\n",
      "  [0.82614999 0.96564522]\n",
      "  [0.94165059 0.98846948]\n",
      "  [0.54491885 0.98363325]\n",
      "  [0.65097404 0.98744747]\n",
      "  [0.79902324 0.99277198]\n",
      "  [0.93254601 0.99757405]]\n",
      "\n",
      " [[0.01636675 0.45508115]\n",
      "  [0.01255253 0.34902596]\n",
      "  [0.00722802 0.20097676]\n",
      "  [0.00242595 0.06745399]\n",
      "  [0.07779114 0.39365676]\n",
      "  [0.05966216 0.30191633]\n",
      "  [0.03435478 0.17385001]\n",
      "  [0.01153052 0.05834941]\n",
      "  [0.15793281 0.31351509]\n",
      "  [0.12112708 0.24045141]\n",
      "  [0.06974762 0.13845717]\n",
      "  [0.02340945 0.04647049]\n",
      "  [0.2193572  0.2520907 ]\n",
      "  [0.16823672 0.19334178]\n",
      "  [0.09687437 0.11133041]\n",
      "  [0.03251402 0.03736591]]\n",
      "\n",
      " [[0.98363325 0.54491885]\n",
      "  [0.98744747 0.65097404]\n",
      "  [0.99277198 0.79902324]\n",
      "  [0.99757405 0.93254601]\n",
      "  [0.92220886 0.60634324]\n",
      "  [0.94033784 0.69808367]\n",
      "  [0.96564522 0.82614999]\n",
      "  [0.98846948 0.94165059]\n",
      "  [0.84206719 0.68648491]\n",
      "  [0.87887292 0.75954859]\n",
      "  [0.93025238 0.86154283]\n",
      "  [0.97659055 0.95352951]\n",
      "  [0.7806428  0.7479093 ]\n",
      "  [0.83176328 0.80665822]\n",
      "  [0.90312563 0.88866959]\n",
      "  [0.96748598 0.96263409]]\n",
      "\n",
      " [[0.48363325 0.54491885]\n",
      "  [0.48744747 0.65097404]\n",
      "  [0.49277198 0.79902324]\n",
      "  [0.49757405 0.93254601]\n",
      "  [0.42220886 0.60634324]\n",
      "  [0.44033784 0.69808367]\n",
      "  [0.46564522 0.82614999]\n",
      "  [0.48846948 0.94165059]\n",
      "  [0.34206719 0.68648491]\n",
      "  [0.37887292 0.75954859]\n",
      "  [0.43025238 0.86154283]\n",
      "  [0.47659055 0.95352951]\n",
      "  [0.2806428  0.7479093 ]\n",
      "  [0.33176328 0.80665822]\n",
      "  [0.40312563 0.88866959]\n",
      "  [0.46748598 0.96263409]]\n",
      "\n",
      " [[0.04491885 0.51636675]\n",
      "  [0.15097404 0.51255253]\n",
      "  [0.29902324 0.50722802]\n",
      "  [0.43254601 0.50242595]\n",
      "  [0.10634324 0.57779114]\n",
      "  [0.19808367 0.55966216]\n",
      "  [0.32614999 0.53435478]\n",
      "  [0.44165059 0.51153052]\n",
      "  [0.18648491 0.65793281]\n",
      "  [0.25954859 0.62112708]\n",
      "  [0.36154283 0.56974762]\n",
      "  [0.45352951 0.52340945]\n",
      "  [0.2479093  0.7193572 ]\n",
      "  [0.30665822 0.66823672]\n",
      "  [0.38866959 0.59687437]\n",
      "  [0.46263409 0.53251402]]\n",
      "\n",
      " [[0.54491885 0.51636675]\n",
      "  [0.65097404 0.51255253]\n",
      "  [0.79902324 0.50722802]\n",
      "  [0.93254601 0.50242595]\n",
      "  [0.60634324 0.57779114]\n",
      "  [0.69808367 0.55966216]\n",
      "  [0.82614999 0.53435478]\n",
      "  [0.94165059 0.51153052]\n",
      "  [0.68648491 0.65793281]\n",
      "  [0.75954859 0.62112708]\n",
      "  [0.86154283 0.56974762]\n",
      "  [0.95352951 0.52340945]\n",
      "  [0.7479093  0.7193572 ]\n",
      "  [0.80665822 0.66823672]\n",
      "  [0.88866959 0.59687437]\n",
      "  [0.96263409 0.53251402]]\n",
      "\n",
      " [[0.51636675 0.95508115]\n",
      "  [0.51255253 0.84902596]\n",
      "  [0.50722802 0.70097676]\n",
      "  [0.50242595 0.56745399]\n",
      "  [0.57779114 0.89365676]\n",
      "  [0.55966216 0.80191633]\n",
      "  [0.53435478 0.67385001]\n",
      "  [0.51153052 0.55834941]\n",
      "  [0.65793281 0.81351509]\n",
      "  [0.62112708 0.74045141]\n",
      "  [0.56974762 0.63845717]\n",
      "  [0.52340945 0.54647049]\n",
      "  [0.7193572  0.7520907 ]\n",
      "  [0.66823672 0.69334178]\n",
      "  [0.59687437 0.61133041]\n",
      "  [0.53251402 0.53736591]]\n",
      "\n",
      " [[0.98363325 0.04491885]\n",
      "  [0.98744747 0.15097404]\n",
      "  [0.99277198 0.29902324]\n",
      "  [0.99757405 0.43254601]\n",
      "  [0.92220886 0.10634324]\n",
      "  [0.94033784 0.19808367]\n",
      "  [0.96564522 0.32614999]\n",
      "  [0.98846948 0.44165059]\n",
      "  [0.84206719 0.18648491]\n",
      "  [0.87887292 0.25954859]\n",
      "  [0.93025238 0.36154283]\n",
      "  [0.97659055 0.45352951]\n",
      "  [0.7806428  0.2479093 ]\n",
      "  [0.83176328 0.30665822]\n",
      "  [0.90312563 0.38866959]\n",
      "  [0.96748598 0.46263409]]\n",
      "\n",
      " [[0.54491885 0.01636675]\n",
      "  [0.65097404 0.01255253]\n",
      "  [0.79902324 0.00722802]\n",
      "  [0.93254601 0.00242595]\n",
      "  [0.60634324 0.07779114]\n",
      "  [0.69808367 0.05966216]\n",
      "  [0.82614999 0.03435478]\n",
      "  [0.94165059 0.01153052]\n",
      "  [0.68648491 0.15793281]\n",
      "  [0.75954859 0.12112708]\n",
      "  [0.86154283 0.06974762]\n",
      "  [0.95352951 0.02340945]\n",
      "  [0.7479093  0.2193572 ]\n",
      "  [0.80665822 0.16823672]\n",
      "  [0.88866959 0.09687437]\n",
      "  [0.96263409 0.03251402]]], shape=(16, 16, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(vp.xy_quad_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "tf.Tensor(\n",
      "[[0.14053908 0.06477376]\n",
      " [0.1398656  0.06489953]\n",
      " [0.13879058 0.06516189]\n",
      " [0.13769998 0.06548262]\n",
      " [0.14125826 0.06665144]\n",
      " [0.14060402 0.06666468]\n",
      " [0.13937527 0.06644172]\n",
      " [0.1379476  0.06599223]\n",
      " [0.14074791 0.06745514]\n",
      " [0.14072709 0.06797565]\n",
      " [0.13986874 0.06777488]\n",
      " [0.13824169 0.06661883]\n",
      " [0.13911804 0.06676487]\n",
      " [0.14010245 0.068184  ]\n",
      " [0.14002146 0.06852717]\n",
      " [0.13844402 0.06706912]\n",
      " [0.12720955 0.04530028]\n",
      " [0.13107027 0.05119612]\n",
      " [0.13580989 0.05799375]\n",
      " [0.13911953 0.06245768]\n",
      " [0.1288511  0.04617314]\n",
      " [0.13211836 0.05165328]\n",
      " [0.13625929 0.05809914]\n",
      " [0.13923066 0.06245097]\n",
      " [0.13083711 0.04753137]\n",
      " [0.13339729 0.05237312]\n",
      " [0.13681719 0.05827452]\n",
      " [0.13937251 0.06244614]\n",
      " [0.1322336  0.04873326]\n",
      " [0.13430641 0.05301705]\n",
      " [0.13722227 0.05843777]\n",
      " [0.13947879 0.06244545]\n",
      " [0.14235416 0.06467457]\n",
      " [0.14273611 0.06522793]\n",
      " [0.14207477 0.06434789]\n",
      " [0.14027262 0.06200746]\n",
      " [0.1424276  0.06497427]\n",
      " [0.14267744 0.0653046 ]\n",
      " [0.14197484 0.06429076]\n",
      " [0.14022784 0.06196483]\n",
      " [0.14236407 0.06550363]\n",
      " [0.14250423 0.06548382]\n",
      " [0.14181094 0.06424119]\n",
      " [0.1401655  0.06191187]\n",
      " [0.14219946 0.06600583]\n",
      " [0.14229977 0.06567828]\n",
      " [0.14165991 0.06422182]\n",
      " [0.14011472 0.06187329]\n",
      " [0.14206377 0.06566816]\n",
      " [0.14126201 0.06359683]\n",
      " [0.13854514 0.05857732]\n",
      " [0.134595   0.05199433]\n",
      " [0.14212547 0.06505515]\n",
      " [0.14108708 0.06299584]\n",
      " [0.13824502 0.05811708]\n",
      " [0.1344282  0.05180396]\n",
      " [0.14205572 0.0643839 ]\n",
      " [0.14076817 0.06229502]\n",
      " [0.13782216 0.05754818]\n",
      " [0.13420691 0.05155957]\n",
      " [0.14188097 0.06397812]\n",
      " [0.14045206 0.06182667]\n",
      " [0.13747384 0.05713736]\n",
      " [0.1340345  0.05137536]\n",
      " [0.13655405 0.06466264]\n",
      " [0.13757851 0.06442007]\n",
      " [0.13887771 0.06418311]\n",
      " [0.13990068 0.06407492]\n",
      " [0.13294496 0.0604268 ]\n",
      " [0.13511652 0.06149697]\n",
      " [0.13770151 0.06276302]\n",
      " [0.1395772  0.06367805]\n",
      " [0.12676115 0.05274807]\n",
      " [0.13101444 0.05640332]\n",
      " [0.13586566 0.06048421]\n",
      " [0.13912105 0.06311263]\n",
      " [0.12117277 0.04541801]\n",
      " [0.12730059 0.05159338]\n",
      " [0.13424485 0.05842059]\n",
      " [0.1387458  0.06264297]\n",
      " [0.13906133 0.06270499]\n",
      " [0.13670979 0.0595879 ]\n",
      " [0.13251392 0.05373974]\n",
      " [0.12806297 0.04714501]\n",
      " [0.13502529 0.05878863]\n",
      " [0.13304283 0.05573177]\n",
      " [0.13001108 0.05087941]\n",
      " [0.12713169 0.04601233]\n",
      " [0.12756007 0.05118907]\n",
      " [0.1270377  0.04928975]\n",
      " [0.12638229 0.04671397]\n",
      " [0.12588057 0.04449002]\n",
      " [0.12032316 0.04361379]\n",
      " [0.12158865 0.04335836]\n",
      " [0.12334229 0.04320965]\n",
      " [0.12489481 0.04329004]\n",
      " [0.1083478  0.01299233]\n",
      " [0.10948253 0.01914992]\n",
      " [0.11224951 0.02834746]\n",
      " [0.11571643 0.03695888]\n",
      " [0.11277954 0.02196661]\n",
      " [0.11333073 0.02608722]\n",
      " [0.11475465 0.03230317]\n",
      " [0.11661157 0.03824166]\n",
      " [0.11904839 0.03322219]\n",
      " [0.11853748 0.03476558]\n",
      " [0.11802665 0.03728458]\n",
      " [0.1177729  0.03988886]\n",
      " [0.12395597 0.04121755]\n",
      " [0.12253515 0.04099557]\n",
      " [0.12050832 0.04093755]\n",
      " [0.1186568  0.04113002]\n",
      " [0.13872404 0.06151212]\n",
      " [0.13598364 0.05829001]\n",
      " [0.13108969 0.05268923]\n",
      " [0.12582135 0.04681537]\n",
      " [0.13877673 0.06088228]\n",
      " [0.13602747 0.05776418]\n",
      " [0.1311342  0.05236691]\n",
      " [0.12584626 0.04670523]\n",
      " [0.13867873 0.06017908]\n",
      " [0.13598817 0.0571424 ]\n",
      " [0.13116165 0.05196524]\n",
      " [0.12587553 0.04656341]\n",
      " [0.13846898 0.05973098]\n",
      " [0.13588017 0.0567156 ]\n",
      " [0.13115824 0.05167204]\n",
      " [0.12589542 0.04645618]\n",
      " [0.13059612 0.04581357]\n",
      " [0.12584387 0.03837485]\n",
      " [0.11831708 0.02662279]\n",
      " [0.11092544 0.01502178]\n",
      " [0.12904506 0.04446876]\n",
      " [0.12435934 0.0372114 ]\n",
      " [0.11722245 0.02585798]\n",
      " [0.11048646 0.01474175]\n",
      " [0.12685504 0.04292927]\n",
      " [0.12232349 0.03582952]\n",
      " [0.11576093 0.02490949]\n",
      " [0.1099099  0.01438234]\n",
      " [0.12505561 0.04192197]\n",
      " [0.12069114 0.03487802]\n",
      " [0.11461619 0.02422092]\n",
      " [0.10946513 0.01411146]\n",
      " [0.1376603  0.06462332]\n",
      " [0.13529996 0.06068581]\n",
      " [0.1307461  0.05403866]\n",
      " [0.12570633 0.04724957]\n",
      " [0.13804946 0.06371264]\n",
      " [0.13554806 0.06000638]\n",
      " [0.13086035 0.0536703 ]\n",
      " [0.1257392  0.04713468]\n",
      " [0.13844753 0.0626273 ]\n",
      " [0.1358016  0.05917708]\n",
      " [0.13098395 0.05320721]\n",
      " [0.12577904 0.04698663]\n",
      " [0.13865353 0.06187955]\n",
      " [0.13593553 0.05858742]\n",
      " [0.13105795 0.05286606]\n",
      " [0.1258072  0.04687458]\n",
      " [0.14106334 0.06448555]\n",
      " [0.14235407 0.06546373]\n",
      " [0.14224994 0.06472731]\n",
      " [0.14042031 0.06218764]\n",
      " [0.14155109 0.06438077]\n",
      " [0.1425456  0.06531833]\n",
      " [0.14223605 0.06460347]\n",
      " [0.14038552 0.06213814]\n",
      " [0.14202938 0.0644096 ]\n",
      " [0.14269877 0.0652186 ]\n",
      " [0.14218435 0.06446854]\n",
      " [0.14033621 0.06207627]\n",
      " [0.14227053 0.06455501]\n",
      " [0.14274067 0.06520954]\n",
      " [0.14211885 0.06438525]\n",
      " [0.14029542 0.06203091]\n",
      " [0.1334805  0.05064365]\n",
      " [0.13521831 0.05428624]\n",
      " [0.13767776 0.0589851 ]\n",
      " [0.13959995 0.06256679]\n",
      " [0.136619   0.05591689]\n",
      " [0.13757951 0.05794446]\n",
      " [0.13890134 0.06070244]\n",
      " [0.13993654 0.06300185]\n",
      " [0.13995254 0.061149  ]\n",
      " [0.14009577 0.06166136]\n",
      " [0.14025802 0.06255772]\n",
      " [0.14034385 0.06352329]\n",
      " [0.14170776 0.0637476 ]\n",
      " [0.14149914 0.06364301]\n",
      " [0.14109857 0.06367637]\n",
      " [0.14063114 0.06388736]\n",
      " [0.14107177 0.06514506]\n",
      " [0.14149904 0.06650403]\n",
      " [0.14099283 0.06719244]\n",
      " [0.13930857 0.06655253]\n",
      " [0.14198351 0.06615808]\n",
      " [0.14167521 0.06659263]\n",
      " [0.14063474 0.06668552]\n",
      " [0.13904427 0.06621898]\n",
      " [0.14149082 0.06538563]\n",
      " [0.14088528 0.06549317]\n",
      " [0.13982668 0.06563899]\n",
      " [0.13866201 0.06574324]\n",
      " [0.13985624 0.06331651]\n",
      " [0.13952855 0.06379091]\n",
      " [0.13895597 0.06455882]\n",
      " [0.13834084 0.06534829]\n",
      " [0.13966394 0.06122812]\n",
      " [0.14154861 0.06374544]\n",
      " [0.1425269  0.06549882]\n",
      " [0.14155806 0.06506484]\n",
      " [0.139854   0.06163848]\n",
      " [0.14158397 0.06403833]\n",
      " [0.14243724 0.06563781]\n",
      " [0.14148726 0.0650984 ]\n",
      " [0.13992748 0.06229691]\n",
      " [0.141531   0.0644987 ]\n",
      " [0.14228934 0.06584804]\n",
      " [0.14139163 0.06514577]\n",
      " [0.13985654 0.06289614]\n",
      " [0.14141768 0.06491158]\n",
      " [0.14215299 0.06603131]\n",
      " [0.14131588 0.06518482]\n",
      " [0.13438077 0.06919837]\n",
      " [0.13732278 0.0705532 ]\n",
      " [0.13920462 0.07013383]\n",
      " [0.13884478 0.06767426]\n",
      " [0.13533895 0.06830046]\n",
      " [0.13794078 0.06983094]\n",
      " [0.13948268 0.06970362]\n",
      " [0.13891988 0.06752963]\n",
      " [0.13657261 0.0672415 ]\n",
      " [0.13872745 0.06895214]\n",
      " [0.13983482 0.06916211]\n",
      " [0.13901631 0.06734304]\n",
      " [0.13748708 0.06652714]\n",
      " [0.13930723 0.06833186]\n",
      " [0.14009506 0.06876303]\n",
      " [0.13908896 0.06720167]\n",
      " [0.12028902 0.04537333]\n",
      " [0.12362567 0.05180225]\n",
      " [0.12814072 0.05998872]\n",
      " [0.13165699 0.06622973]\n",
      " [0.12602547 0.05280895]\n",
      " [0.12785004 0.05698082]\n",
      " [0.13030201 0.06244949]\n",
      " [0.13226047 0.06686975]\n",
      " [0.13237883 0.06061086]\n",
      " [0.132544   0.06250772]\n",
      " [0.13278625 0.06520818]\n",
      " [0.13300452 0.06765055]\n",
      " [0.13609664 0.06492704]\n",
      " [0.13539715 0.06572073]\n",
      " [0.13441434 0.06696502]\n",
      " [0.13354105 0.06820717]], shape=(256, 2), dtype=float64)\n",
      "tf.Tensor([16 16  2], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "n_triangles=vp.n_triangles\n",
    "xy_quad_total =vp.xy_quad_total\n",
    "\n",
    "print(n_triangles)\n",
    "\n",
    "\n",
    "x_eval=tf.reshape(vp.xy_quad_total,(-1,2))\n",
    "grad=vp.eval_grad_NN(x_eval)\n",
    "\n",
    "print(grad)\n",
    "\n",
    "grad=tf.reshape(grad,(n_triangles,-1,2))\n",
    "\n",
    "print(tf.shape(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.14053908 0.1398656  0.13879058 0.13769998 0.14125826 0.14060402\n",
      "  0.13937527 0.1379476  0.14074791 0.14072709 0.13986874 0.13824169\n",
      "  0.13911804 0.14010245 0.14002146 0.13844402]\n",
      " [0.06477376 0.06489953 0.06516189 0.06548262 0.06665144 0.06666468\n",
      "  0.06644172 0.06599223 0.06745514 0.06797565 0.06777488 0.06661883\n",
      "  0.06676487 0.068184   0.06852717 0.06706912]], shape=(2, 16), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.1400985 ]\n",
      " [0.06687384]], shape=(2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "grad_elem=tf.transpose(grad[0])\n",
    "print(grad_elem)\n",
    "\n",
    "print(grad_elem @vp.w_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.04713674 0.07077614 0.0451681  0.01084645 0.08837018 0.13268843\n",
      "  0.08467945 0.02033452 0.08837018 0.13268843 0.08467945 0.02033452\n",
      "  0.04713674 0.07077614 0.0451681  0.01084645]\n",
      " [1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.        ]], shape=(2, 16), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w_quad = tf.concat([vp.w_quad.T, tf.ones_like(vp.w_quad.T)], axis=0)\n",
    "print(w_quad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2, 16), dtype=float64, numpy=\n",
       "array([[[-2.50971524, -1.69178745, -0.54998993,  0.47977568,\n",
       "         -1.52692501, -0.93803331, -0.11596185,  0.62544886,\n",
       "         -0.24465821,  0.04540536,  0.45032358,  0.81551168,\n",
       "          0.73813202,  0.79915951,  0.88435166,  0.96118486],\n",
       "        [-2.50971524, -1.69178745, -0.54998993,  0.47977568,\n",
       "         -1.52692501, -0.93803331, -0.11596185,  0.62544886,\n",
       "         -0.24465821,  0.04540536,  0.45032358,  0.81551168,\n",
       "          0.73813202,  0.79915951,  0.88435166,  0.96118486]],\n",
       "\n",
       "       [[-0.77158322,  0.10737205,  1.33436173,  2.44096054,\n",
       "         -0.77158322,  0.10737205,  1.33436173,  2.44096054,\n",
       "         -0.77158322,  0.10737205,  1.33436173,  2.44096054,\n",
       "         -0.77158322,  0.10737205,  1.33436173,  2.44096054],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.73813202, -0.79915951, -0.88435166, -0.96118486,\n",
       "          0.24465821, -0.04540536, -0.45032358, -0.81551168,\n",
       "          1.52692501,  0.93803331,  0.11596185, -0.62544886,\n",
       "          2.50971524,  1.69178745,  0.54998993, -0.47977568]],\n",
       "\n",
       "       [[ 3.28129845,  1.5844154 , -0.7843718 , -2.92073623,\n",
       "          2.29850822,  0.83066125, -1.21839988, -3.06640941,\n",
       "          1.01624142, -0.15277742, -1.78468531, -3.25647222,\n",
       "          0.03345119, -0.90653156, -2.21871339, -3.4021454 ],\n",
       "        [-0.22841678, -1.10737205, -2.33436173, -3.44096054,\n",
       "         -0.22841678, -1.10737205, -2.33436173, -3.44096054,\n",
       "         -0.22841678, -1.10737205, -2.33436173, -3.44096054,\n",
       "         -0.22841678, -1.10737205, -2.33436173, -3.44096054]],\n",
       "\n",
       "       [[ 0.26186798,  0.20084049,  0.11564834,  0.03881514,\n",
       "          1.24465821,  0.95459464,  0.54967642,  0.18448832,\n",
       "          2.52692501,  1.93803331,  1.11596185,  0.37455114,\n",
       "          3.50971524,  2.69178745,  1.54998993,  0.52022432],\n",
       "        [ 0.22841678,  1.10737205,  2.33436173,  3.44096054,\n",
       "          0.22841678,  1.10737205,  2.33436173,  3.44096054,\n",
       "          0.22841678,  1.10737205,  2.33436173,  3.44096054,\n",
       "          0.22841678,  1.10737205,  2.33436173,  3.44096054]],\n",
       "\n",
       "       [[-0.26186798, -0.20084049, -0.11564834, -0.03881514,\n",
       "         -1.24465821, -0.95459464, -0.54967642, -0.18448832,\n",
       "         -2.52692501, -1.93803331, -1.11596185, -0.37455114,\n",
       "         -3.50971524, -2.69178745, -1.54998993, -0.52022432],\n",
       "        [ 3.24784726,  2.49094696,  1.4343416 ,  0.48140918,\n",
       "          1.2822668 ,  0.98343867,  0.56628544,  0.19006282,\n",
       "         -1.2822668 , -0.98343867, -0.56628544, -0.19006282,\n",
       "         -3.24784726, -2.49094696, -1.4343416 , -0.48140918]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.grad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 12,  9],\n",
       "       [ 8,  4,  5],\n",
       "       [10,  7,  3],\n",
       "       [ 3,  5, 10],\n",
       "       [12,  4,  6],\n",
       "       [ 4,  8,  6],\n",
       "       [ 0,  6,  8],\n",
       "       [11,  2,  7],\n",
       "       [ 5,  0,  8],\n",
       "       [ 9,  2, 11],\n",
       "       [ 4,  7, 10],\n",
       "       [ 5,  4, 10],\n",
       "       [ 4,  9, 11],\n",
       "       [ 7,  4, 11],\n",
       "       [ 1,  9, 12],\n",
       "       [ 6,  1, 12]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.mesh['triangles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(vp.mesh['triangles'][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6737555926196086, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Iteration: 0 loss: 0.6737555926 time: 0.24459028244018555\n",
      "tf.Tensor(0.668136113687304, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6701878576324535, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6697408182630031, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.668493024454393, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6677878502570475, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676508524929976, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6677798746629727, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.667933672441401, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6680004646093882, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6679699182732114, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6678797037914384, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6677735084248323, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676814142999103, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676168116729337, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675807293706231, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675675595991326, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675696172710037, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675798271898579, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675927093204942, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676043896861081, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676124096304359, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676156077074507, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676138881351608, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6676077603053844, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675978857690432, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675848910268724, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675693508222191, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675516966150394, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675320853897482, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6675104513087926, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6674867104632233, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6674608436482258, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6674327897065705, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6674023687206163, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6673693085158231, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6673331411760697, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6672927703737754, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6672457729491263, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.667187605494342, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6671109029221892, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6670052086824904, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6668573012188124, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6666512386552411, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6663650992944331, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6659569065958483, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.665335178932493, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6643308114119328, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6626819269543485, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6599786918456885, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.655438376040648, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6478634703648056, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6360890378452002, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.6187804748438102, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.5962866361894288, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.5998380379094231, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.5315005345958729, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.5771184594830511, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.4645853081015742, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.5054469295465404, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.38569235342438324, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.4774154102114247, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.36375919331359435, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.42816147405110294, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.42151559256611637, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3690011434948195, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.4352278959801911, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.36097669944119304, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.38867094060915325, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.39062745070465427, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3515133776461578, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.38870883013132385, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3586021870119144, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3545145744239713, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.36949376500104764, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.34123188596019455, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3547047822007413, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.35275698814075557, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.34170352380264946, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.35798868494829866, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.34024023448283724, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.34544071144771715, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3414916365758934, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.332620710968739, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3408706464723277, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32924275862395597, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3386739721021625, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.33154600249048155, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3338858761293704, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3333213361035122, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3287704978455842, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3325797336490505, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32642697749427224, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3311045441264618, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.325179020380058, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3294132613982225, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3241539739108719, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3274664912274594, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32391101278263573, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3267296233617409, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3239491091699527, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Iteration: 100 loss: 0.3239491092 time: 7.810904026031494\n",
      "tf.Tensor(0.32579589210824406, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3233814140087043, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32442424529724295, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3224401891012225, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3234157146579709, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3221434571135589, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32303374736292323, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3219086349373083, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32248610996305643, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32151284813423037, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32193921233629214, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32116187237715904, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3214763788469722, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32080175210112416, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32100062276204516, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32044100561548605, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3206826011814714, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32022413991962384, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.32039746875967645, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31986885792774267, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3199438623956778, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31943557691189817, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31951513200712084, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31906245517238263, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3190954224776814, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31864666044223156, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3186096477874479, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31819950363317934, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31809175411864904, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31770578096000834, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3174815814481552, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31713776070443617, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3168327593109081, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31654513060929235, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3161577180356781, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31586248702046066, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3154007073968634, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31506270534514286, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31458059908028935, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31416081728964484, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3136625452953044, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31313744919654385, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31262461046600765, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3120128805415149, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31142941381069567, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3107424457585258, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.31004372541624853, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.30929855242559456, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.30847439069858773, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.307633412589769, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.30669271723724373, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3057013655650435, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3046443390935036, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3034716726663827, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.30222732956798637, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3008731220633376, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2993819082514314, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.29776853863166347, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.29599014063551055, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2940144737396651, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2918317299594837, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.28939462703973085, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2866509582900634, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.28355784813200563, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2800588287094199, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.27607427044872257, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2715025400475921, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.26626228611116043, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.26024766266565147, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.25333098064260046, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.24542468896807323, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.23643213942431462, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.22637740351643237, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2153673843510105, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.20361717460048379, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.1914575745696252, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.17917469226837246, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.16976352972397915, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.2126054280608985, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.41222353580362253, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.16764236660212206, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.3219026836786435, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.16508682305259675, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.17356293448794227, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.19291340671555743, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.13571882866342821, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.1483626677719811, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.1731789331975181, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.14038818111363338, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.11313817798717497, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.12519826727637517, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.1276638448466593, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.09008786548395174, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.07665257065236657, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.08721636113895449, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.07648543544201913, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.04967234956663301, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.03807882788249116, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.039923705762907324, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.030378439460686586, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Iteration: 200 loss: 0.0303784395 time: 7.935587644577026\n",
      "tf.Tensor(0.01607731429729649, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.018164355555321123, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.023257797800610658, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.019252546688228366, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.020717525175252695, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.07535322554020368, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.40862843603834376, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.18359066323563172, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0903766318381663, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.11117038441121987, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.10287565723000232, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.03533320651317152, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0697810778805268, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.08944733673173634, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.07192670460978313, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.050228785109765, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.08311421714380948, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.05445118572260557, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.03059682801724091, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.05102345611445663, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0445629482252779, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.028215887822931232, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.02638544743591159, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.028217290267174865, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.028286293317013978, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.020388057712361917, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.015606308713047717, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.026496404647549612, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.021407251720309318, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.010605705156785397, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.01926437234117101, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.022661518347773874, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.01400388284474272, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.013583621325392975, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.018969113013517242, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.015262997231849837, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.01285025063813288, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.01497430850734491, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.01437302413362853, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.012410643154593066, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.012421713671649409, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.012193407502724315, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.011656322125853708, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.011563946021487168, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.010704873374190002, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.010435176851624275, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.010936161258029539, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.009886482275373278, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.008889753060290335, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.009903295993954163, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.009871904289286899, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.008426638988459781, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.008533449376112067, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.008997215663907078, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.008257073327489255, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.007973421661305484, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00813952155011356, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.007711439800970006, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0074413125665672075, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.007499517458888799, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.007229693979426427, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0070305999056390536, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006894415171199388, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006653353259327713, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006657827818295449, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006530733923193575, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0061723433765956464, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006157962186254088, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.006127266965241198, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00582643230225773, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.005752749988280837, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0056941881219852875, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0054458149821819376, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.005383070428735769, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.005320115608359472, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.005117629079883438, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0050211877259874905, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004937421903782589, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0048199377733484546, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004732998052198282, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004609190306490405, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0045237137131091615, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00444543410294591, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004328595375811471, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004265655371866542, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004175182258543234, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.004068088030248538, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00402062004407933, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.003927364052245235, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0038345318451467702, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.003780358831827615, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0036965934856858346, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.003625973116273684, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0035601208651339054, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0034849495170410872, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.003423721970352553, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0033578267226188085, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0032982152386781672, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0032337027900091395, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0031713152654339223, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Iteration: 300 loss: 0.0031713153 time: 7.956099033355713\n",
      "tf.Tensor(0.0031208215644877284, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00305705350019822, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.003003637537929312, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0029518078105112157, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002894319065163835, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002848068453344162, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002795293988839069, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0027455285355901604, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002699973253340365, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0026525962559864843, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0026077997344141723, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002562509943174911, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002520448662918051, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002477339902155743, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0024369147629657493, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0023966356831530656, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0023560846539924774, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002319506789325033, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002280642900152422, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0022444302650710527, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002208703824729573, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0021732405225715376, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0021395687246625393, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002105530699292035, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0020728044040886078, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.002040531688118535, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0020093118232561704, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0019780233506202557, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0019479723354378206, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0019181704354719823, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0018889963821526485, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0018606901870273594, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0018322809686231161, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0018051228549561108, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001777986424474396, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001751569079872824, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001725552503256593, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001700034700930638, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0016749981966367184, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0016504245789021057, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0016262100833164116, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0016024865882450457, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0015792373474560245, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0015562520765150724, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001533852347296405, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0015116519406373431, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0014900146295764194, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0014686263220160343, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001447649593635346, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001427026922799427, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0014067603077118468, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0013868171183339254, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0013672272466388078, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0013479367973103014, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001329003160121339, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0013103635142888918, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0012920228347113448, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0012740136220822293, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0012562639994111134, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0012388413790097846, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0012216673005544004, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001204799257183289, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001188192638936337, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0011718590794494697, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0011557827146583554, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0011399762441689364, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0011244129020311206, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0011091146707690948, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010940420453938262, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010792303177897245, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010646408881356093, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010502945326342317, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.001036169830743638, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010222745529980697, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0010085981498822567, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009951402270631888, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009818927740105421, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000968860201196117, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009560283631062659, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009434048570462722, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009309749785981177, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009187465200369133, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0009067067938978718, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008948586512405244, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008831953381352726, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008717163900403405, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008604168571728704, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008492950118625109, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008383464671132733, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000827570831020308, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008169619695668188, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0008065204623683059, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007962402821091603, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000786121978748974, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007761601870562124, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007663543077191894, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007567005930433226, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007471971238120874, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007378411961134249, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007286304216083999, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Iteration: 400 loss: 0.0007286304 time: 8.036771059036255\n",
      "tf.Tensor(0.0007195626498428927, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007106353204575814, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0007018461802264866, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006931930887403959, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006846737242001851, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000676285987543268, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006680275661460865, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000659896481312637, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006518907176619785, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006440080635982652, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006362467388874553, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006286044493556887, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006210796327341495, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006136699710365034, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0006063739520681726, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005991894040141678, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005921147664726575, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005851480839976134, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005782876975401726, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005715318316658042, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005648787320744022, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005583268107965645, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005518743260572352, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005455197690333602, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005392614096479209, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005330977895795391, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005270272772191347, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005210484134521286, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005151596409593709, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005093595103746856, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0005036465752203503, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0004980193982708069, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0004924765926303765, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00048701673836101637, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00048163850993884045, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0004763405353520956, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00047112152788625, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0004659801627216656, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.000460915184662195, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.00045592533206735396, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "tf.Tensor(0.0004510093750543242, shape=(), dtype=float64)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mariano/Documenti/progetto serio/IVPINN/temp_mariano/mesh_final.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history\u001b[39m=\u001b[39mvp\u001b[39m.\u001b[39;49mtrain(\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documenti/progetto serio/IVPINN/temp_mariano/VPINN_tri_final.py:350\u001b[0m, in \u001b[0;36mVPINN.train\u001b[0;34m(self, iter)\u001b[0m\n\u001b[1;32m    347\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    348\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39miter\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 350\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_descent()\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    352\u001b[0m         elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documenti/progetto serio/IVPINN/temp_mariano/VPINN_tri_final.py:333\u001b[0m, in \u001b[0;36mVPINN.gradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient_descent\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 333\u001b[0m     loss, gradient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_gradient()\n\u001b[1;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradient, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNN\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documenti/progetto serio/IVPINN/temp_mariano/VPINN_tri_final.py:324\u001b[0m, in \u001b[0;36mVPINN.loss_gradient\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m    322\u001b[0m     \u001b[39m#loss_grad.watch(self.xy_quad_total)\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     tape\u001b[39m.\u001b[39mwatch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvars)\n\u001b[0;32m--> 324\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_total()\n\u001b[1;32m    325\u001b[0m     \u001b[39mprint\u001b[39m(loss)\n\u001b[1;32m    326\u001b[0m     \u001b[39m#loss=(tf.reduce_sum(tf.square(res_vertices))+tf.reduce_sum(tf.square(res_edges)))/self.dof\u001b[39;00m\n",
      "File \u001b[0;32m~/Documenti/progetto serio/IVPINN/temp_mariano/VPINN_tri_final.py:313\u001b[0m, in \u001b[0;36mVPINN.loss_total\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_total\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    311\u001b[0m     \u001b[39m#loss_b = self.boundary_loss(tape)\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[39m#res = self.variational_loss(tape)\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     res\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_loss()\n\u001b[1;32m    314\u001b[0m     \u001b[39mreturn\u001b[39;00m  res\n",
      "File \u001b[0;32m~/Documenti/progetto serio/IVPINN/temp_mariano/VPINN_tri_final.py:148\u001b[0m, in \u001b[0;36mVPINN.custom_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m grad_test_elem\u001b[39m=\u001b[39mB_D \u001b[39m@\u001b[39m grad_test\n\u001b[1;32m    147\u001b[0m v0\u001b[39m=\u001b[39m J\u001b[39m*\u001b[39mtf\u001b[39m.\u001b[39mreduce_sum(w_quad\u001b[39m*\u001b[39mgrad_test_elem[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mgrad_elem)\n\u001b[0;32m--> 148\u001b[0m v1\u001b[39m=\u001b[39m J\u001b[39m*\u001b[39mtf\u001b[39m.\u001b[39;49mreduce_sum(w_quad\u001b[39m*\u001b[39;49mgrad_test_elem[\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49mgrad_elem)\n\u001b[1;32m    149\u001b[0m v2\u001b[39m=\u001b[39m J\u001b[39m*\u001b[39mtf\u001b[39m.\u001b[39mreduce_sum(w_quad\u001b[39m*\u001b[39mgrad_test_elem[\u001b[39m2\u001b[39m]\u001b[39m*\u001b[39mgrad_elem)\n\u001b[1;32m    151\u001b[0m l0\u001b[39m=\u001b[39mJ\u001b[39m*\u001b[39mtf\u001b[39m.\u001b[39mreduce_sum(w_quad\u001b[39m*\u001b[39mgrad_test_elem[\u001b[39m3\u001b[39m]\u001b[39m*\u001b[39mgrad_elem)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:2393\u001b[0m, in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_sum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_sum\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2330\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2332\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m \n\u001b[1;32m   2334\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.add` op.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2389\u001b[0m \u001b[39m  @end_compatibility\u001b[39;00m\n\u001b[1;32m   2390\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m   2392\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m-> 2393\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:2230\u001b[0m, in \u001b[0;36m_ReductionDims\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   2228\u001b[0m \u001b[39m# Fast path: avoid creating Rank and Range ops if ndims is known.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m \u001b[39mif\u001b[39;00m x_rank:\n\u001b[0;32m-> 2230\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(np\u001b[39m.\u001b[39;49marange(x_rank, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mint32))\n\u001b[1;32m   2231\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2232\u001b[0m   \u001b[39m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, array_ops\u001b[39m.\u001b[39mrank(x))\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    284\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    286\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=vp.train(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = tf.constant([[[triangle[0],1]], [[triangle[1],1]], [[triangle[2],1]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'dense/kernel:0' shape=(2, 10) dtype=float64, numpy=\n",
      "array([[-0.18118578, -0.03227072,  0.36894768,  0.59652931, -0.60875419,\n",
      "         0.56420617,  0.55500679, -0.19522076,  0.19865682,  0.27736105],\n",
      "       [ 0.54101937,  0.31275726,  0.63924457, -0.54636931, -0.04391798,\n",
      "        -0.26106643,  0.43464894,  0.33500951, -0.51474341,  0.24451667]])>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([ 0.46175455, -0.35997278,  0.50573092,  0.18425817,  0.02005263,\n",
      "        0.06511641,  0.32058967, -0.25942829, -0.49469555,  0.52924059])>, <tf.Variable 'dense_1/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[-0.38510916, -0.2969549 ,  0.329789  , -0.06660554,  0.28572387,\n",
      "         0.58459917,  0.3478867 ,  0.12018525, -0.49258947,  0.26725967],\n",
      "       [-0.24918572,  0.07491062,  0.02084466,  0.0460839 , -0.14781953,\n",
      "         0.27055481, -0.37032448, -0.33589525, -0.44973867, -0.20998315],\n",
      "       [ 0.08889845,  0.34708803,  0.07734863,  0.19044017, -0.11488259,\n",
      "        -0.22958414,  0.0252627 , -0.30388043,  0.27743452, -0.39595236],\n",
      "       [-0.44331509, -0.14830168, -0.17781552,  0.37268599, -0.19016595,\n",
      "        -0.04788486, -0.18520274, -0.11170105,  0.28364294, -0.01591845],\n",
      "       [-0.44705349,  0.32169819,  0.56350051, -0.47997112, -0.50430281,\n",
      "         0.23968864, -0.35681216, -0.36111726,  0.2780196 ,  0.28856178],\n",
      "       [-0.03976073,  0.30392381,  0.49487208,  0.30570848,  0.18487403,\n",
      "         0.27812137, -0.28812843, -0.48182762,  0.36031162,  0.51607692],\n",
      "       [ 0.1484583 ,  0.16023245,  0.17678419, -0.45015012, -0.11082649,\n",
      "        -0.27013813, -0.49889403, -0.40152639,  0.35014825,  0.52491474],\n",
      "       [-0.11439728,  0.51544158, -0.17764975,  0.23320673,  0.09125047,\n",
      "         0.36161285, -0.34196007,  0.23612038,  0.49642886,  0.04302573],\n",
      "       [ 0.15055885,  0.34222385,  0.40337097, -0.3985135 ,  0.04119829,\n",
      "        -0.12226323, -0.33661384, -0.50358893, -0.31883732,  0.37755761],\n",
      "       [ 0.50751444,  0.49021757,  0.20901913, -0.42797835, -0.09831608,\n",
      "        -0.27824078, -0.05906424,  0.0469047 , -0.3605075 , -0.25551073]])>, <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([ 0.21700489,  0.011165  , -0.04060204, -0.00934006, -0.0076187 ,\n",
      "        0.06838514, -0.58328065,  0.15676325,  0.42795741, -0.11303419])>, <tf.Variable 'dense_2/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[-0.19658356,  0.10053537,  0.31421543, -0.03619412,  0.01667329,\n",
      "        -0.21382057,  0.41359279, -0.47607576,  0.15946463, -0.33157707],\n",
      "       [ 0.01687727,  0.33409841,  0.30245536, -0.3597573 , -0.00098729,\n",
      "        -0.04302022, -0.37441745,  0.42530126, -0.26863081,  0.19039471],\n",
      "       [-0.27540554, -0.24327929,  0.42341349, -0.43913765,  0.02866536,\n",
      "         0.25080064, -0.40485505, -0.00385673, -0.10728149,  0.29346386],\n",
      "       [ 0.0599065 , -0.11613574,  0.49687312, -0.33348569,  0.17968706,\n",
      "         0.48911039, -0.21167539,  0.43755477, -0.19192078, -0.41101771],\n",
      "       [-0.3032222 , -0.27438472,  0.49754996, -0.24381666,  0.0225522 ,\n",
      "        -0.02061121, -0.41425164, -0.15133407,  0.31898951,  0.2086436 ],\n",
      "       [ 0.02191514, -0.11200326,  0.0625074 ,  0.49703237,  0.16657372,\n",
      "         0.38718877, -0.22977089,  0.0567066 , -0.45566639, -0.58675601],\n",
      "       [-0.39853396, -0.45299865,  0.558678  , -0.28584924,  0.25951839,\n",
      "         0.10972072,  0.46626274, -0.42821566,  0.05200488, -0.18595651],\n",
      "       [-0.28820286,  0.22286119,  0.10480201, -0.05909735, -0.0711108 ,\n",
      "        -0.15102081, -0.34837292,  0.32563968,  0.04346777,  0.47833761],\n",
      "       [ 0.02188094, -0.0120881 , -0.20252178,  0.53694363,  0.11129217,\n",
      "        -0.08370066,  0.03037558,  0.32689192, -0.40910869, -0.03794735],\n",
      "       [-0.27216951, -0.03679481,  0.08241336,  0.12796094, -0.21865731,\n",
      "        -0.2645719 ,  0.51981988,  0.38278898,  0.13219565,  0.29896101]])>, <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([-0.04182743,  0.06324374,  0.29747288, -0.43260752,  0.50958366,\n",
      "        0.37993819, -0.4580797 , -0.43996754,  0.00281547, -0.02758446])>, <tf.Variable 'dense_3/kernel:0' shape=(10, 10) dtype=float64, numpy=\n",
      "array([[-0.09248101, -0.29083153,  0.36642921,  0.0083841 , -0.00429925,\n",
      "        -0.25183227, -0.43812771,  0.16871456,  0.11709303,  0.27131227],\n",
      "       [-0.38956548,  0.27797402,  0.49067954,  0.37711724,  0.41713792,\n",
      "        -0.27019758, -0.50356118, -0.01341611,  0.12323103,  0.53315825],\n",
      "       [ 0.4652484 , -0.22158631, -0.37562218, -0.48385823,  0.25633851,\n",
      "        -0.11745022, -0.09449291, -0.04681026,  0.01426372,  0.31803181],\n",
      "       [-0.12079747,  0.35519174, -0.51088153, -0.29106006,  0.19637557,\n",
      "        -0.45972795,  0.45873284, -0.47241048, -0.20135319, -0.23283839],\n",
      "       [ 0.02649182,  0.41161727, -0.23864756,  0.52034623,  0.21012895,\n",
      "         0.33684912,  0.19391069, -0.25454825, -0.52634654, -0.50349498],\n",
      "       [ 0.250275  , -0.47539263,  0.03738146, -0.32145247,  0.2837309 ,\n",
      "         0.49083943,  0.2324371 ,  0.43836463,  0.59499126,  0.06847818],\n",
      "       [-0.38910285,  0.42849622, -0.12207857, -0.41731779, -0.2965018 ,\n",
      "         0.36785798,  0.06561329,  0.45516835,  0.05271798, -0.01567221],\n",
      "       [ 0.02300892, -0.27623715,  0.36858106,  0.20914804, -0.04653006,\n",
      "        -0.28719259, -0.53673439, -0.15414113, -0.03364288, -0.09038777],\n",
      "       [-0.14446976, -0.47318988, -0.30719214,  0.49347464, -0.51547126,\n",
      "        -0.21677411, -0.49803591,  0.36813127, -0.47406653, -0.03085009],\n",
      "       [-0.39251382,  0.03155806, -0.40511872, -0.43487124,  0.00133547,\n",
      "        -0.09992842,  0.39027156,  0.25513865,  0.19846681,  0.21451893]])>, <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float64, numpy=\n",
      "array([-0.09567077, -0.49654252, -0.22883533, -0.50462944, -0.16012988,\n",
      "        0.19748162,  0.12719131,  0.05184182, -0.48209264, -0.46663451])>, <tf.Variable 'dense_4/kernel:0' shape=(10, 1) dtype=float64, numpy=\n",
      "array([[-0.26168393],\n",
      "       [-0.27128488],\n",
      "       [ 0.04763193],\n",
      "       [ 0.09759675],\n",
      "       [-0.34553903],\n",
      "       [ 0.49328879],\n",
      "       [ 0.10284192],\n",
      "       [-0.60865947],\n",
      "       [ 0.06297939],\n",
      "       [ 0.24849285]])>, <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float64, numpy=array([-0.52327706])>]\n"
     ]
    }
   ],
   "source": [
    "print(vp.NN.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5 1 1 1]], shape=(1, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-1.98576243e+00]\n",
      " [-1.98552141e+00]\n",
      " [-2.28600487e-07]\n",
      " [-2.75298903e+00]\n",
      " [-2.22044605e-16]\n",
      " [-4.47290951e+00]\n",
      " [ 2.75294757e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 4.47290951e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 4.46689186e+00]\n",
      " [-2.78867744e+00]\n",
      " [-1.98578880e+00]\n",
      " [-2.75298903e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-4.46689186e+00]\n",
      " [ 1.98552539e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.98578880e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]\n",
      " [ 1.98555322e+00]\n",
      " [ 2.78872579e+00]\n",
      " [ 2.75299062e+00]\n",
      " [ 1.98576107e+00]\n",
      " [ 0.00000000e+00]\n",
      " [-1.98555322e+00]\n",
      " [ 0.00000000e+00]], shape=(28, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 1,1, 1]])    # tf.rank(tensor) == 2\n",
    "indices = [[0,0]]           # num_updates == 2, index_depth == 2\n",
    "updates = [5]                    # num_updates == 2\n",
    "print(tf.tensor_scatter_nd_update(tensor, indices, updates))\n",
    "\n",
    "print(vp.F_total_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(320, 2), dtype=float64, numpy=\n",
       "array([[0.    , 0.    ],\n",
       "       [0.0125, 0.    ],\n",
       "       [0.025 , 0.    ],\n",
       "       [0.0375, 0.    ],\n",
       "       [0.05  , 0.    ],\n",
       "       [0.0625, 0.    ],\n",
       "       [0.075 , 0.    ],\n",
       "       [0.0875, 0.    ],\n",
       "       [0.1   , 0.    ],\n",
       "       [0.1125, 0.    ],\n",
       "       [0.125 , 0.    ],\n",
       "       [0.1375, 0.    ],\n",
       "       [0.15  , 0.    ],\n",
       "       [0.1625, 0.    ],\n",
       "       [0.175 , 0.    ],\n",
       "       [0.1875, 0.    ],\n",
       "       [0.2   , 0.    ],\n",
       "       [0.2125, 0.    ],\n",
       "       [0.225 , 0.    ],\n",
       "       [0.2375, 0.    ],\n",
       "       [0.25  , 0.    ],\n",
       "       [0.2625, 0.    ],\n",
       "       [0.275 , 0.    ],\n",
       "       [0.2875, 0.    ],\n",
       "       [0.3   , 0.    ],\n",
       "       [0.3125, 0.    ],\n",
       "       [0.325 , 0.    ],\n",
       "       [0.3375, 0.    ],\n",
       "       [0.35  , 0.    ],\n",
       "       [0.3625, 0.    ],\n",
       "       [0.375 , 0.    ],\n",
       "       [0.3875, 0.    ],\n",
       "       [0.4   , 0.    ],\n",
       "       [0.4125, 0.    ],\n",
       "       [0.425 , 0.    ],\n",
       "       [0.4375, 0.    ],\n",
       "       [0.45  , 0.    ],\n",
       "       [0.4625, 0.    ],\n",
       "       [0.475 , 0.    ],\n",
       "       [0.4875, 0.    ],\n",
       "       [0.5   , 0.    ],\n",
       "       [0.5125, 0.    ],\n",
       "       [0.525 , 0.    ],\n",
       "       [0.5375, 0.    ],\n",
       "       [0.55  , 0.    ],\n",
       "       [0.5625, 0.    ],\n",
       "       [0.575 , 0.    ],\n",
       "       [0.5875, 0.    ],\n",
       "       [0.6   , 0.    ],\n",
       "       [0.6125, 0.    ],\n",
       "       [0.625 , 0.    ],\n",
       "       [0.6375, 0.    ],\n",
       "       [0.65  , 0.    ],\n",
       "       [0.6625, 0.    ],\n",
       "       [0.675 , 0.    ],\n",
       "       [0.6875, 0.    ],\n",
       "       [0.7   , 0.    ],\n",
       "       [0.7125, 0.    ],\n",
       "       [0.725 , 0.    ],\n",
       "       [0.7375, 0.    ],\n",
       "       [0.75  , 0.    ],\n",
       "       [0.7625, 0.    ],\n",
       "       [0.775 , 0.    ],\n",
       "       [0.7875, 0.    ],\n",
       "       [0.8   , 0.    ],\n",
       "       [0.8125, 0.    ],\n",
       "       [0.825 , 0.    ],\n",
       "       [0.8375, 0.    ],\n",
       "       [0.85  , 0.    ],\n",
       "       [0.8625, 0.    ],\n",
       "       [0.875 , 0.    ],\n",
       "       [0.8875, 0.    ],\n",
       "       [0.9   , 0.    ],\n",
       "       [0.9125, 0.    ],\n",
       "       [0.925 , 0.    ],\n",
       "       [0.9375, 0.    ],\n",
       "       [0.95  , 0.    ],\n",
       "       [0.9625, 0.    ],\n",
       "       [0.975 , 0.    ],\n",
       "       [0.9875, 0.    ],\n",
       "       [1.    , 0.    ],\n",
       "       [1.    , 0.0125],\n",
       "       [1.    , 0.025 ],\n",
       "       [1.    , 0.0375],\n",
       "       [1.    , 0.05  ],\n",
       "       [1.    , 0.0625],\n",
       "       [1.    , 0.075 ],\n",
       "       [1.    , 0.0875],\n",
       "       [1.    , 0.1   ],\n",
       "       [1.    , 0.1125],\n",
       "       [1.    , 0.125 ],\n",
       "       [1.    , 0.1375],\n",
       "       [1.    , 0.15  ],\n",
       "       [1.    , 0.1625],\n",
       "       [1.    , 0.175 ],\n",
       "       [1.    , 0.1875],\n",
       "       [1.    , 0.2   ],\n",
       "       [1.    , 0.2125],\n",
       "       [1.    , 0.225 ],\n",
       "       [1.    , 0.2375],\n",
       "       [1.    , 0.25  ],\n",
       "       [1.    , 0.2625],\n",
       "       [1.    , 0.275 ],\n",
       "       [1.    , 0.2875],\n",
       "       [1.    , 0.3   ],\n",
       "       [1.    , 0.3125],\n",
       "       [1.    , 0.325 ],\n",
       "       [1.    , 0.3375],\n",
       "       [1.    , 0.35  ],\n",
       "       [1.    , 0.3625],\n",
       "       [1.    , 0.375 ],\n",
       "       [1.    , 0.3875],\n",
       "       [1.    , 0.4   ],\n",
       "       [1.    , 0.4125],\n",
       "       [1.    , 0.425 ],\n",
       "       [1.    , 0.4375],\n",
       "       [1.    , 0.45  ],\n",
       "       [1.    , 0.4625],\n",
       "       [1.    , 0.475 ],\n",
       "       [1.    , 0.4875],\n",
       "       [1.    , 0.5   ],\n",
       "       [1.    , 0.5125],\n",
       "       [1.    , 0.525 ],\n",
       "       [1.    , 0.5375],\n",
       "       [1.    , 0.55  ],\n",
       "       [1.    , 0.5625],\n",
       "       [1.    , 0.575 ],\n",
       "       [1.    , 0.5875],\n",
       "       [1.    , 0.6   ],\n",
       "       [1.    , 0.6125],\n",
       "       [1.    , 0.625 ],\n",
       "       [1.    , 0.6375],\n",
       "       [1.    , 0.65  ],\n",
       "       [1.    , 0.6625],\n",
       "       [1.    , 0.675 ],\n",
       "       [1.    , 0.6875],\n",
       "       [1.    , 0.7   ],\n",
       "       [1.    , 0.7125],\n",
       "       [1.    , 0.725 ],\n",
       "       [1.    , 0.7375],\n",
       "       [1.    , 0.75  ],\n",
       "       [1.    , 0.7625],\n",
       "       [1.    , 0.775 ],\n",
       "       [1.    , 0.7875],\n",
       "       [1.    , 0.8   ],\n",
       "       [1.    , 0.8125],\n",
       "       [1.    , 0.825 ],\n",
       "       [1.    , 0.8375],\n",
       "       [1.    , 0.85  ],\n",
       "       [1.    , 0.8625],\n",
       "       [1.    , 0.875 ],\n",
       "       [1.    , 0.8875],\n",
       "       [1.    , 0.9   ],\n",
       "       [1.    , 0.9125],\n",
       "       [1.    , 0.925 ],\n",
       "       [1.    , 0.9375],\n",
       "       [1.    , 0.95  ],\n",
       "       [1.    , 0.9625],\n",
       "       [1.    , 0.975 ],\n",
       "       [1.    , 0.9875],\n",
       "       [1.    , 1.    ],\n",
       "       [0.9875, 1.    ],\n",
       "       [0.975 , 1.    ],\n",
       "       [0.9625, 1.    ],\n",
       "       [0.95  , 1.    ],\n",
       "       [0.9375, 1.    ],\n",
       "       [0.925 , 1.    ],\n",
       "       [0.9125, 1.    ],\n",
       "       [0.9   , 1.    ],\n",
       "       [0.8875, 1.    ],\n",
       "       [0.875 , 1.    ],\n",
       "       [0.8625, 1.    ],\n",
       "       [0.85  , 1.    ],\n",
       "       [0.8375, 1.    ],\n",
       "       [0.825 , 1.    ],\n",
       "       [0.8125, 1.    ],\n",
       "       [0.8   , 1.    ],\n",
       "       [0.7875, 1.    ],\n",
       "       [0.775 , 1.    ],\n",
       "       [0.7625, 1.    ],\n",
       "       [0.75  , 1.    ],\n",
       "       [0.7375, 1.    ],\n",
       "       [0.725 , 1.    ],\n",
       "       [0.7125, 1.    ],\n",
       "       [0.7   , 1.    ],\n",
       "       [0.6875, 1.    ],\n",
       "       [0.675 , 1.    ],\n",
       "       [0.6625, 1.    ],\n",
       "       [0.65  , 1.    ],\n",
       "       [0.6375, 1.    ],\n",
       "       [0.625 , 1.    ],\n",
       "       [0.6125, 1.    ],\n",
       "       [0.6   , 1.    ],\n",
       "       [0.5875, 1.    ],\n",
       "       [0.575 , 1.    ],\n",
       "       [0.5625, 1.    ],\n",
       "       [0.55  , 1.    ],\n",
       "       [0.5375, 1.    ],\n",
       "       [0.525 , 1.    ],\n",
       "       [0.5125, 1.    ],\n",
       "       [0.5   , 1.    ],\n",
       "       [0.4875, 1.    ],\n",
       "       [0.475 , 1.    ],\n",
       "       [0.4625, 1.    ],\n",
       "       [0.45  , 1.    ],\n",
       "       [0.4375, 1.    ],\n",
       "       [0.425 , 1.    ],\n",
       "       [0.4125, 1.    ],\n",
       "       [0.4   , 1.    ],\n",
       "       [0.3875, 1.    ],\n",
       "       [0.375 , 1.    ],\n",
       "       [0.3625, 1.    ],\n",
       "       [0.35  , 1.    ],\n",
       "       [0.3375, 1.    ],\n",
       "       [0.325 , 1.    ],\n",
       "       [0.3125, 1.    ],\n",
       "       [0.3   , 1.    ],\n",
       "       [0.2875, 1.    ],\n",
       "       [0.275 , 1.    ],\n",
       "       [0.2625, 1.    ],\n",
       "       [0.25  , 1.    ],\n",
       "       [0.2375, 1.    ],\n",
       "       [0.225 , 1.    ],\n",
       "       [0.2125, 1.    ],\n",
       "       [0.2   , 1.    ],\n",
       "       [0.1875, 1.    ],\n",
       "       [0.175 , 1.    ],\n",
       "       [0.1625, 1.    ],\n",
       "       [0.15  , 1.    ],\n",
       "       [0.1375, 1.    ],\n",
       "       [0.125 , 1.    ],\n",
       "       [0.1125, 1.    ],\n",
       "       [0.1   , 1.    ],\n",
       "       [0.0875, 1.    ],\n",
       "       [0.075 , 1.    ],\n",
       "       [0.0625, 1.    ],\n",
       "       [0.05  , 1.    ],\n",
       "       [0.0375, 1.    ],\n",
       "       [0.025 , 1.    ],\n",
       "       [0.0125, 1.    ],\n",
       "       [0.    , 1.    ],\n",
       "       [0.    , 0.9875],\n",
       "       [0.    , 0.975 ],\n",
       "       [0.    , 0.9625],\n",
       "       [0.    , 0.95  ],\n",
       "       [0.    , 0.9375],\n",
       "       [0.    , 0.925 ],\n",
       "       [0.    , 0.9125],\n",
       "       [0.    , 0.9   ],\n",
       "       [0.    , 0.8875],\n",
       "       [0.    , 0.875 ],\n",
       "       [0.    , 0.8625],\n",
       "       [0.    , 0.85  ],\n",
       "       [0.    , 0.8375],\n",
       "       [0.    , 0.825 ],\n",
       "       [0.    , 0.8125],\n",
       "       [0.    , 0.8   ],\n",
       "       [0.    , 0.7875],\n",
       "       [0.    , 0.775 ],\n",
       "       [0.    , 0.7625],\n",
       "       [0.    , 0.75  ],\n",
       "       [0.    , 0.7375],\n",
       "       [0.    , 0.725 ],\n",
       "       [0.    , 0.7125],\n",
       "       [0.    , 0.7   ],\n",
       "       [0.    , 0.6875],\n",
       "       [0.    , 0.675 ],\n",
       "       [0.    , 0.6625],\n",
       "       [0.    , 0.65  ],\n",
       "       [0.    , 0.6375],\n",
       "       [0.    , 0.625 ],\n",
       "       [0.    , 0.6125],\n",
       "       [0.    , 0.6   ],\n",
       "       [0.    , 0.5875],\n",
       "       [0.    , 0.575 ],\n",
       "       [0.    , 0.5625],\n",
       "       [0.    , 0.55  ],\n",
       "       [0.    , 0.5375],\n",
       "       [0.    , 0.525 ],\n",
       "       [0.    , 0.5125],\n",
       "       [0.    , 0.5   ],\n",
       "       [0.    , 0.4875],\n",
       "       [0.    , 0.475 ],\n",
       "       [0.    , 0.4625],\n",
       "       [0.    , 0.45  ],\n",
       "       [0.    , 0.4375],\n",
       "       [0.    , 0.425 ],\n",
       "       [0.    , 0.4125],\n",
       "       [0.    , 0.4   ],\n",
       "       [0.    , 0.3875],\n",
       "       [0.    , 0.375 ],\n",
       "       [0.    , 0.3625],\n",
       "       [0.    , 0.35  ],\n",
       "       [0.    , 0.3375],\n",
       "       [0.    , 0.325 ],\n",
       "       [0.    , 0.3125],\n",
       "       [0.    , 0.3   ],\n",
       "       [0.    , 0.2875],\n",
       "       [0.    , 0.275 ],\n",
       "       [0.    , 0.2625],\n",
       "       [0.    , 0.25  ],\n",
       "       [0.    , 0.2375],\n",
       "       [0.    , 0.225 ],\n",
       "       [0.    , 0.2125],\n",
       "       [0.    , 0.2   ],\n",
       "       [0.    , 0.1875],\n",
       "       [0.    , 0.175 ],\n",
       "       [0.    , 0.1625],\n",
       "       [0.    , 0.15  ],\n",
       "       [0.    , 0.1375],\n",
       "       [0.    , 0.125 ],\n",
       "       [0.    , 0.1125],\n",
       "       [0.    , 0.1   ],\n",
       "       [0.    , 0.0875],\n",
       "       [0.    , 0.075 ],\n",
       "       [0.    , 0.0625],\n",
       "       [0.    , 0.05  ],\n",
       "       [0.    , 0.0375],\n",
       "       [0.    , 0.025 ],\n",
       "       [0.    , 0.0125]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.boundary_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([1.0 ,2.0])\n",
    "\n",
    "\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([6., 2.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "b=tf.Variable([1.0 ,2.0])\n",
    "\n",
    "print(b)\n",
    "\n",
    "b[0].assign(6.0)\n",
    "\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.0, shape=(), dtype=float32) tf.Tensor(12.0, shape=(), dtype=float32) 12\n"
     ]
    }
   ],
   "source": [
    "x=tf.constant(6.0)\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    res=f(x)\n",
    "grad=tape.gradient(res,x)\n",
    "\n",
    "\n",
    "print(res,grad,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float32' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mariano/Documenti/progetto serio/IVPINN/temp_mariano/mesh_final.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     res\u001b[39m=\u001b[39mf(z)        \u001b[39m#(x+y)^2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     temp\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(res)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grad\u001b[39m=\u001b[39mtape\u001b[39m.\u001b[39;49mgradient(res,x)  \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#grad_=tape.gradient(temp,x)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X44sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(res,grad)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1058\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1059\u001b[0m           output_gradients))\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1061\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1063\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1065\u001b[0m     flat_targets,\n\u001b[1;32m   1066\u001b[0m     flat_sources,\n\u001b[1;32m   1067\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1068\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1069\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1072\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float32' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(3.0)\n",
    "y=tf.Variable(1.0)\n",
    "\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    #y.assign_add(x)\n",
    "    z=x+y\n",
    "    res=f(z)        #(x+y)^2\n",
    "    temp=np.array(res)\n",
    "\n",
    "grad=tape.gradient(res,x)  \n",
    "#grad_=tape.gradient(temp,x)\n",
    "\n",
    "\n",
    "print(res,grad)\n",
    "print(grad_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Passed in object 3.0 of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mariano/Documenti/progetto serio/IVPINN/temp_mariano/mesh_final.ipynb Cell 34\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m*\u001b[39mx\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m#y.assign_add(x)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     tape\u001b[39m.\u001b[39;49mwatch(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     res\u001b[39m=\u001b[39mf(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grad\u001b[39m=\u001b[39mtape\u001b[39m.\u001b[39mgradient(res,x)   \n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:871\u001b[0m, in \u001b[0;36mGradientTape.watch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwatch\u001b[39m(\u001b[39mself\u001b[39m, tensor):\n\u001b[1;32m    863\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Ensures that `tensor` is being traced by this tape.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \n\u001b[1;32m    865\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39m    ValueError: if it encounters something that is not a tensor.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m   \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m _extract_tensors_and_variables(tensor):\n\u001b[1;32m    872\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m backprop_util\u001b[39m.\u001b[39mIsTrainable(t):\n\u001b[1;32m    873\u001b[0m       logging\u001b[39m.\u001b[39mlog_first_n(\n\u001b[1;32m    874\u001b[0m           logging\u001b[39m.\u001b[39mWARN, \u001b[39m\"\u001b[39m\u001b[39mThe dtype of the watched tensor must be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    875\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mfloating (e.g. tf.float32), got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m, t\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documenti/test/base/lib/python3.9/site-packages/tensorflow/python/eager/backprop.py:698\u001b[0m, in \u001b[0;36m_extract_tensors_and_variables\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    696\u001b[0m   \u001b[39myield from\u001b[39;00m _extract_tensors_and_variables(components)\n\u001b[1;32m    697\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassed in object \u001b[39m\u001b[39m{\u001b[39;00mobj\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    699\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, not tf.Tensor or tf.Variable or ExtensionType.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Passed in object 3.0 of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType."
     ]
    }
   ],
   "source": [
    "x=.constant(3.0)\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    #y.assign_add(x)\n",
    "    tape.watch(x)\n",
    "    res=f(x)\n",
    "\n",
    "\n",
    "grad=tape.gradient(res,x)   \n",
    "\n",
    "\n",
    "print(res,grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mariano/Documenti/progetto serio/IVPINN/temp_mariano/mesh_final.ipynb Cell 35\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconstant((\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mariano/Documenti/progetto%20serio/IVPINN/temp_mariano/mesh_final.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x[\u001b[39m0\u001b[39;49m]\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "x=tf.constant((1,2))\n",
    "\n",
    "print(x)\n",
    "\n",
    "x[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]]\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the row vector\n",
    "vector_length = 10\n",
    "\n",
    "# Specify the indices where you want to place non-zero values\n",
    "non_zero_indices = tf.constant([[2], [5], [8]], dtype=tf.int32)\n",
    "\n",
    "# Specify the values to be placed at the specified indices\n",
    "non_zero_values = tf.constant([[1.0], [2.0], [3.0]], dtype=tf.float32)\n",
    "\n",
    "# Create the row vector with zeros and the specified values\n",
    "row_vector = tf.scatter_nd(non_zero_indices, non_zero_values, shape=(vector_length,1))\n",
    "\n",
    "# Print the result\n",
    "print(row_vector.numpy())\n",
    "\n",
    "\n",
    "print(row_vector[1][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 2) dtype=float64, numpy=array([[0., 0.]])>\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(tf.zeros((1,2),dtype=tf.float64))\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
