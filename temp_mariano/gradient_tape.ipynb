{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 16:50:41.331302: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-16 16:50:41.332745: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 16:50:41.367635: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-16 16:50:41.368989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 16:50:42.005152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval tf.Tensor([[-0.9589243]], shape=(1, 1), dtype=float32)\n",
      "der_eval tf.Tensor([[0.2836622 0.5673244]], shape=(1, 2), dtype=float32)\n",
      "tf_der tf.Tensor([[0.2836622 0.5673244]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the function f(x) = x A x^T\n",
    "A = tf.constant([[1.0, 2.0]], dtype=tf.float32)\n",
    "def f(x,A):\n",
    "\n",
    "    return tf.sin(x@tf.transpose(A))  # Ax vector classic\n",
    "\n",
    "\n",
    "# Generate some input data\n",
    "x = tf.Variable([[1.0,2.0]])\n",
    "\n",
    "\n",
    "print('eval',f(x,A))\n",
    "print('der_eval',A*tf.cos(x@tf.transpose(A)))\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    res=f(x,A)\n",
    "der=tape.gradient(res,x)\n",
    "\n",
    "print('tf_der',der)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval x tf.Tensor([[-0.9589243]], shape=(1, 1), dtype=float32)\n",
      "der_eval x tf.Tensor([[0.2836622 0.5673244]], shape=(1, 2), dtype=float32)\n",
      "eval y tf.Tensor([[0.1498772]], shape=(1, 1), dtype=float32)\n",
      "der_eval x tf.Tensor([[0.9887046 1.9774092]], shape=(1, 2), dtype=float32)\n",
      "\n",
      "tf_der x tf.Tensor([[0.2836622 0.5673244]], shape=(1, 2), dtype=float32)\n",
      "tf_der y tf.Tensor([[0.9887046 1.9774092]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the function f(x) = x A x^T\n",
    "A = tf.constant([[1.0, 2.0]], dtype=tf.float32)\n",
    "def f(x,A):\n",
    "\n",
    "    return tf.sin(x@tf.transpose(A))  # Ax vector classic\n",
    "\n",
    "\n",
    "# Generate some input data\n",
    "x = tf.Variable([[1.0,2.0]])\n",
    "y= tf.Variable([[5.0,7.0]])\n",
    "\n",
    "\n",
    "\n",
    "print('eval x',f(x,A))\n",
    "print('der_eval x',A*tf.cos(x@tf.transpose(A)))\n",
    "\n",
    "print('eval y',f(y,A))\n",
    "print('der_eval x',A*tf.cos(y@tf.transpose(A)))\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    tape.watch(y)\n",
    "    resx=f(x,A)\n",
    "    resy=f(y,A)\n",
    "    \n",
    "derx=tape.gradient(resx,x)\n",
    "dery=tape.gradient(resy,y)\n",
    "\n",
    "\n",
    "print('tf_der x',derx)\n",
    "print('tf_der y',dery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.2836622 ]\n",
      "  [ 0.9887046 ]\n",
      "  [-0.27516335]]\n",
      "\n",
      " [[ 0.2836622 ]\n",
      "  [ 0.9887046 ]\n",
      "  [-0.27516335]]], shape=(2, 3, 1), dtype=float32)\n",
      "eval  tf.Tensor(\n",
      "[[[-0.9589243 ]\n",
      "  [ 0.1498772 ]\n",
      "  [-0.96139747]]\n",
      "\n",
      " [[-0.9589243 ]\n",
      "  [ 0.1498772 ]\n",
      "  [-0.96139747]]], shape=(2, 3, 1), dtype=float32)\n",
      "der_eval  tf.Tensor(\n",
      "[[[ 0.2836622   0.5673244 ]\n",
      "  [ 0.9887046   1.9774092 ]\n",
      "  [-0.27516335 -0.5503267 ]]\n",
      "\n",
      " [[ 0.2836622   0.5673244 ]\n",
      "  [ 0.9887046   1.9774092 ]\n",
      "  [-0.27516335 -0.5503267 ]]], shape=(2, 3, 2), dtype=float32)\n",
      "\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "tf_der tf.Tensor(\n",
      "[[[ 0.2836622   0.5673244 ]\n",
      "  [ 0.9887046   1.9774092 ]\n",
      "  [-0.27516335 -0.5503267 ]]\n",
      "\n",
      " [[ 0.2836622   0.5673244 ]\n",
      "  [ 0.9887046   1.9774092 ]\n",
      "  [-0.27516335 -0.5503267 ]]], shape=(2, 3, 2), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the function f(x) = x A x^T\n",
    "A = tf.constant([[1.0, 2.0]], dtype=tf.float32)\n",
    "\n",
    "def f(x,A):\n",
    "\n",
    "    return tf.sin(x@tf.transpose(A))  # Ax vector classic\n",
    "\n",
    "\n",
    "# Generate some input data\n",
    "v = tf.Variable([[[1.0,2.0],[5.0,7.0],[3.0,7.0]],[[1.0,2.0],[5.0,7.0],[3.0,7.0]]])\n",
    "\n",
    "print(tf.cos(v@tf.transpose(A)))\n",
    "\n",
    "print('eval ',f(v,A))\n",
    "print('der_eval ',A*tf.cos(v@tf.transpose(A)))\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(v)\n",
    "    res=f(v,A)\n",
    "    \n",
    "    der=tape.gradient(res,v)\n",
    "derder=tape.gradient(der,v)\n",
    "\n",
    "\n",
    "print('tf_der',der)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
